{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 4294967296\n",
      "free     : 61288448\n",
      "used     : 4233678848\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate distr from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "p = \"../handler/data/pickled/0.2x5DHfL/eegAndStage.No_Hf_l_1.pkl\"\n",
    "with open(p,\"rb\") as f:\n",
    "    (eeg, emg, stageSeq, timeStamps) = pickle.load(f)\n",
    "eeg = eeg.reshape(-1,512)\n",
    "pred = \"../results/predictlabels/W6193T_predictOnDel.pickle\"\n",
    "with open(pred,\"rb\") as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neeg = []\n",
    "# for i in range(len(eeg)):\n",
    "#     if stageSeq[i] == \"H\":\n",
    "#         neeg.append(eeg[i])\n",
    "neeg = []\n",
    "for i in range(len(eeg)):\n",
    "    if stageSeq[i] == \"H\" and x[i] ==\"l\":\n",
    "        neeg.append(eeg[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 7 DPSS windows\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "neeg = np.array(neeg)\n",
    "lpsd, lfreqs = mne.time_frequency.psd_array_multitaper(neeg,sfreq=128,fmin=1,fmax=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6508379888268156\n"
     ]
    }
   ],
   "source": [
    "def critical_point(psd, f):# return the 0.5 point of freq cumulation\n",
    "    psd = psd.flatten()\n",
    "    f = f.flatten()\n",
    "    max_ind = 1\n",
    "    max_cp = 0\n",
    "    for cp in range(len(f)):\n",
    "        l = np.sum(psd[:cp])\n",
    "        h = np.sum(psd[cp:])\n",
    "        h_ind = abs((h-l)/(h+l))\n",
    "\n",
    "        if h_ind < max_ind:\n",
    "            max_ind = h_ind\n",
    "            max_cp = cp\n",
    "\n",
    "    return f[max_cp]\n",
    "#ratio over 6 in LTW\n",
    "ct = []\n",
    "for i in lpsd:\n",
    "    ct.append(critical_point(i, lfreqs))\n",
    "\n",
    "d = {x: ct.count(x) for x in ct}\n",
    "data = (dict(sorted(d.items())))\n",
    "# print(dict(sorted(d.items())))\n",
    "sum_over_6 = sum([value for key, value in data.items() if key >= 6])\n",
    "total_sum = sum(data.values())\n",
    "\n",
    "result = sum_over_6 / total_sum\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 19 artists>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = d.keys()\n",
    "n = d.values()\n",
    "plt.bar(f, n, label=\"{}\".format(\"H=>L\"),alpha=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "featurePath = \"run/85J254predict.pickle\"\n",
    "featureFileHandler = open(featurePath, 'rb')\n",
    "features = pickle.load(featureFileHandler)\n",
    "features = [x.upper() if x!= \"n\" else \"S\" for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?', 'H', 'L', 'R', 'S'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split trained files and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/file4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\".csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\".csv\",new_path+\"/\"+i+\".csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels for pre part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/label4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\"_Trend.csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\"_Trend.csv\",new_path+\"/\"+i+\"_Trend.csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,\"..\")\n",
    "print(sys.path)\n",
    "print(\"---------------------------------------------------------\")\n",
    "from utils.dataReader import DataReader\n",
    "import matplotlib.pyplot as plt\n",
    "dataReader = DataReader()\n",
    "# dataReader.readAll(sys)\n",
    "#readOfflineEEGandStageLabels2pickle.py reads text files containing EEG raw data signals and ground truth stage labels from the WAVEDIR directory. It writes files starting with \"eegAndStage\" into the \"data/pickled\" directory. These files are in Python's pickle format to enable faster access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = {\"a\":1,\"b\":2,\"c\":3}\n",
    "ls = [3,2,4,6]\n",
    "ls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data,m, t = dataReader.readEEG(\"../data/sampledata/Raw/D1798_short.txt\")\n",
    "data = np.array(data).reshape(1, -1)      \n",
    "# raw = mne.io.RawArray(data, inf)      \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39mis_available()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(['EEG'], sfreq, 'eeg'))\n",
    "raw.compute_psd(fmin =1,fmax =12).get_data()#.plot()\n",
    "# raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "# raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(ch_names=['EEG'], sfreq=sfreq))\n",
    "seg = eegSegment.reshape((1,-1))\n",
    "seg.shape\n",
    "# Apply STFT\n",
    "frequencies = mne.time_frequency.stft(seg, wsize=nperseg)\n",
    "fr = frequencies[0]\n",
    "f = np.sum(abs(fr),axis = 1)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pcolormesh(segment_times, freqs, np.abs(Zxx),  # shading='gouraud'\n",
    "               )\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "# plt.ylim(fmin, fmax)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(Zxx, freqs, lowerFreq, upperFreq):\n",
    "        zipped = list(filter(lambda x: lowerFreq <=\n",
    "                      x[1] and x[1] < upperFreq, zip(Zxx, freqs)))\n",
    "        return np.array([e[0] for e in zipped]), np.array([e[1] for e in zipped])\n",
    "\n",
    "def binning(Zxx, freqs, freqBinNum):\n",
    "    binSize = np.int(np.floor(1.0 * len(Zxx) / freqBinNum))\n",
    "    Zxx_binned = np.array([np.sum(np.abs(Zxx[(binID*binSize):((binID+1)*binSize)]),axis=0) for binID in range(freqBinNum)])\n",
    "    freqs_binned = np.array([np.mean(freqs[(binID*binSize):((binID+1)*binSize)],axis=0) for binID in range(freqBinNum)])\n",
    "    return Zxx_binned, freqs_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(5)]\n",
    "print(a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot2stageLabel(oneHot, stageLabels4evaluation, stageLabel2stageID):\n",
    "    # print('in oneHot2stageLabel, oneHot.shape = ' + str(oneHot.shape))\n",
    "    # keyList = [keys for keys in params.stageLabel2stageID.keys()]\n",
    "    # print('keyList = ' + str(keyList))\n",
    "    stageID = np.argmax(oneHot)\n",
    "    for key in stageLabels4evaluation:\n",
    "        if stageLabel2stageID[key] == stageID:\n",
    "            return key\n",
    "    return '-'\n",
    "\n",
    "labelCorrectionDict = {'S' : 'n', 'W' : 'w', 'R' : 'r', 'H' :'h', 'RW' : 'w', 'M' : 'm', 'P' : 'P', 'F2' : 'F2', '?' : '?', '-' : '-'}\n",
    "\n",
    "stageLabels4evaluation = orig_stageLabels[:self.maximumStageNum]\n",
    "stageLabel2stageID = {stage: stageID for stage, stageID in zip(\n",
    "    orig_stageLabels[:self.maximumStageNum], range(self.maximumStageNum))}\n",
    "\n",
    "def correct_label(items):\n",
    "    return labelCorrectionDict[oneHot2stageLabel(items[0], stageLabels4evaluation, stageLabel2stageID)]\n",
    "\n",
    "if self.params.classifierType == 'deep':\n",
    "    if type(y_pred_modified) != list and type(y_pred_modified) != np.ndarray:\n",
    "        if y_pred_modified == '?':\n",
    "            y_pred = y_pred_modified\n",
    "        else:\n",
    "            y_pred = correct_label(y_pred_modified)\n",
    "    else:\n",
    "        y_pred = correct_label(y_pred_modified)\n",
    "    # print('after labelCorrection, y_pred =', y_pred)\n",
    "    # print('y_pred = ' + str(y_pred))\n",
    "else:\n",
    "    y_pred = self.params.labelCorrectionDict[y_pred_modified[0]]\n",
    "\n",
    "# print(y_pred, end='')\n",
    "self.pastStages_L.append(y_pred_modified[0])\n",
    "return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCorrectionDict = {'S': 'n', 'W': 'w', 'R': 'r', 'H': 'h',\n",
    "                       'RW': 'w', 'M': 'm', 'P': 'P', 'F2': 'F2', '?': '?', '-': '-'}\n",
    "labelCorrectionDict['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3,5,6,7,11,3,66]\n",
    "import numpy as np\n",
    "np.argmax(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
