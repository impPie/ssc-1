{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total    : 4294967296\n",
      "free     : 61288448\n",
      "used     : 4233678848\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "h = nvmlDeviceGetHandleByIndex(0)\n",
    "info = nvmlDeviceGetMemoryInfo(h)\n",
    "print(f'total    : {info.total}')\n",
    "print(f'free     : {info.free}')\n",
    "print(f'used     : {info.used}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "r-a  # free inside reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "featurePath = \"run/85J254predict.pickle\"\n",
    "featureFileHandler = open(featurePath, 'rb')\n",
    "features = pickle.load(featureFileHandler)\n",
    "features = [x.upper() if x!= \"n\" else \"S\" for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'?', 'H', 'L', 'R', 'S'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split trained files and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/file4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\".csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\".csv\",new_path+\"/\"+i+\".csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels for pre part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/label4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\"_Trend.csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\"_Trend.csv\",new_path+\"/\"+i+\"_Trend.csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,\"..\")\n",
    "print(sys.path)\n",
    "print(\"---------------------------------------------------------\")\n",
    "from utils.dataReader import DataReader\n",
    "import matplotlib.pyplot as plt\n",
    "dataReader = DataReader()\n",
    "# dataReader.readAll(sys)\n",
    "#readOfflineEEGandStageLabels2pickle.py reads text files containing EEG raw data signals and ground truth stage labels from the WAVEDIR directory. It writes files starting with \"eegAndStage\" into the \"data/pickled\" directory. These files are in Python's pickle format to enable faster access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = {\"a\":1,\"b\":2,\"c\":3}\n",
    "ls = [3,2,4,6]\n",
    "ls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data,m, t = dataReader.readEEG(\"../data/sampledata/Raw/D1798_short.txt\")\n",
    "data = np.array(data).reshape(1, -1)      \n",
    "# raw = mne.io.RawArray(data, inf)      \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'cuda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39mis_available()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'cuda'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(['EEG'], sfreq, 'eeg'))\n",
    "raw.compute_psd(fmin =1,fmax =12).get_data()#.plot()\n",
    "# raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "# raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(ch_names=['EEG'], sfreq=sfreq))\n",
    "seg = eegSegment.reshape((1,-1))\n",
    "seg.shape\n",
    "# Apply STFT\n",
    "frequencies = mne.time_frequency.stft(seg, wsize=nperseg)\n",
    "fr = frequencies[0]\n",
    "f = np.sum(abs(fr),axis = 1)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pcolormesh(segment_times, freqs, np.abs(Zxx),  # shading='gouraud'\n",
    "               )\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "# plt.ylim(fmin, fmax)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(Zxx, freqs, lowerFreq, upperFreq):\n",
    "        zipped = list(filter(lambda x: lowerFreq <=\n",
    "                      x[1] and x[1] < upperFreq, zip(Zxx, freqs)))\n",
    "        return np.array([e[0] for e in zipped]), np.array([e[1] for e in zipped])\n",
    "\n",
    "def binning(Zxx, freqs, freqBinNum):\n",
    "    binSize = np.int(np.floor(1.0 * len(Zxx) / freqBinNum))\n",
    "    Zxx_binned = np.array([np.sum(np.abs(Zxx[(binID*binSize):((binID+1)*binSize)]),axis=0) for binID in range(freqBinNum)])\n",
    "    freqs_binned = np.array([np.mean(freqs[(binID*binSize):((binID+1)*binSize)],axis=0) for binID in range(freqBinNum)])\n",
    "    return Zxx_binned, freqs_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(5)]\n",
    "print(a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot2stageLabel(oneHot, stageLabels4evaluation, stageLabel2stageID):\n",
    "    # print('in oneHot2stageLabel, oneHot.shape = ' + str(oneHot.shape))\n",
    "    # keyList = [keys for keys in params.stageLabel2stageID.keys()]\n",
    "    # print('keyList = ' + str(keyList))\n",
    "    stageID = np.argmax(oneHot)\n",
    "    for key in stageLabels4evaluation:\n",
    "        if stageLabel2stageID[key] == stageID:\n",
    "            return key\n",
    "    return '-'\n",
    "\n",
    "labelCorrectionDict = {'S' : 'n', 'W' : 'w', 'R' : 'r', 'H' :'h', 'RW' : 'w', 'M' : 'm', 'P' : 'P', 'F2' : 'F2', '?' : '?', '-' : '-'}\n",
    "\n",
    "stageLabels4evaluation = orig_stageLabels[:self.maximumStageNum]\n",
    "stageLabel2stageID = {stage: stageID for stage, stageID in zip(\n",
    "    orig_stageLabels[:self.maximumStageNum], range(self.maximumStageNum))}\n",
    "\n",
    "def correct_label(items):\n",
    "    return labelCorrectionDict[oneHot2stageLabel(items[0], stageLabels4evaluation, stageLabel2stageID)]\n",
    "\n",
    "if self.params.classifierType == 'deep':\n",
    "    if type(y_pred_modified) != list and type(y_pred_modified) != np.ndarray:\n",
    "        if y_pred_modified == '?':\n",
    "            y_pred = y_pred_modified\n",
    "        else:\n",
    "            y_pred = correct_label(y_pred_modified)\n",
    "    else:\n",
    "        y_pred = correct_label(y_pred_modified)\n",
    "    # print('after labelCorrection, y_pred =', y_pred)\n",
    "    # print('y_pred = ' + str(y_pred))\n",
    "else:\n",
    "    y_pred = self.params.labelCorrectionDict[y_pred_modified[0]]\n",
    "\n",
    "# print(y_pred, end='')\n",
    "self.pastStages_L.append(y_pred_modified[0])\n",
    "return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCorrectionDict = {'S': 'n', 'W': 'w', 'R': 'r', 'H': 'h',\n",
    "                       'RW': 'w', 'M': 'm', 'P': 'P', 'F2': 'F2', '?': '?', '-': '-'}\n",
    "labelCorrectionDict['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3,5,6,7,11,3,66]\n",
    "import numpy as np\n",
    "np.argmax(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
